{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 必要库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models\n",
    "from torchvision.io import read_image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import time\n",
    "\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 引入resnet预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DME\n"
     ]
    }
   ],
   "source": [
    "label_map = {'CNV':0, 'DME':1, 'DRUSEN':2, 'NORMAL':3,}\n",
    "\n",
    "def dict_reverse(dict, value):\n",
    "   return [k for k,v in dict.items() if value==v]\n",
    "   \n",
    "pred = dict_reverse(label_map,1)\n",
    "print(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "3\n",
      "torch.Size([3, 343, 512])\n",
      "torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('OCT-Resnet_model.pth'))\n",
    "# label_map = {'CNV':0, 'DME':1, 'DRUSEN':2, 'NORMAL':3,}\n",
    "label_reverse = { 0:'CNV', 1:'DME', 2:'DRUSEN', 3:'NORAML',}\n",
    "\n",
    "# CNV:脉络膜新生血管\n",
    "# DME:糖尿病性黄斑水肿\n",
    "# DRUSEN:玻璃疣\n",
    "# NORMAL:正常\n",
    "\n",
    "img_path = r'C:\\Users\\LRRRR\\Desktop\\resnet-OCT\\templates\\DRUSEN-1112835-1.jpeg'\n",
    "plt.figure()\n",
    "plt.imread(img_path)\n",
    "plt.show()\n",
    "\n",
    "def transform_img(img_path):\n",
    "        image = read_image(img_path)\n",
    "        print(type(image))\n",
    "        # image = image.squeeze()\n",
    "        print(image.size()[0])\n",
    "        if image.size()[0] == 1:\n",
    "                image = image.repeat(3, 1, 1)\n",
    "        print(image.size())\n",
    "        image = image / 255.0\n",
    "        #print(image)\n",
    "        image = T.Resize((224, 224))(image)\n",
    "        image = image.to(device)\n",
    "        image = image.unsqueeze(0)\n",
    "        print(image.size())\n",
    "        return image\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "        transform_img(img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "3\n",
      "torch.Size([3, 289, 512])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "0\n",
      "CNV\n"
     ]
    }
   ],
   "source": [
    "img_path = r'C:\\Users\\LRRRR\\Desktop\\resnet-OCT\\templates\\CNV-1016042-1.jpeg'\n",
    "with torch.set_grad_enabled(False):\n",
    "        outputs = model(transform_img(img_path))\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        prediction = preds.tolist()[0]\n",
    "        print(prediction)\n",
    "        print(label_reverse[prediction])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ebf9cfd872009544a161647ac82c48f4cc096aba58631b69e515c7576d66293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
